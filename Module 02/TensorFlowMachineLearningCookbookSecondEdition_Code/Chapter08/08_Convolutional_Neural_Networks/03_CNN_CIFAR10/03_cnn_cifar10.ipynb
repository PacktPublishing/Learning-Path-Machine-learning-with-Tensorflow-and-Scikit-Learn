{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Advanced CNN Model: CIFAR-10\n",
    "------------------\n",
    "\n",
    "In this example, we will download the CIFAR-10 images and build a CNN model with dropout and regularization.\n",
    "\n",
    "CIFAR is composed ot 50k train and 10k test images that are 32x32.\n",
    "\n",
    "We start by loading the necessary libaries and resetting any default computational graph that already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import urllib\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, start a new graph session and set the default parameters.\n",
    "\n",
    "List of defaults:\n",
    "\n",
    " - `batch_size`: this is how many cifar examples to train on in one batch.\n",
    " - `data_dir`: where to store data (check if data exists here, as to not have to download every time).\n",
    " - `output_every`: output training accuracy/loss statistics every X generations/epochs.\n",
    " - `eval_every`: output test accuracy/loss statistics every X generations/epochs.\n",
    " - `image_height`: standardize images to this height.\n",
    " - `image_width`: standardize images to this width.\n",
    " - `crop_height`: random internal crop before training on image - height.\n",
    " - `crop_width`: random internal crop before training on image - width.\n",
    " - `num_channels`: number of color channels of image (greyscale = 1, color = 3).\n",
    " - `num_targets`: number of different target categories. CIFAR-10 has 10.\n",
    " - `extract_folder`: folder to extract downloaded images to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a graph session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Set model parameters\n",
    "batch_size = 128\n",
    "data_dir = 'temp'\n",
    "output_every = 50\n",
    "generations = 20000\n",
    "eval_every = 500\n",
    "image_height = 32\n",
    "image_width = 32\n",
    "crop_height = 24\n",
    "crop_width = 24\n",
    "num_channels = 3\n",
    "num_targets = 10\n",
    "extract_folder = 'cifar-10-batches-bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the learning rate, learning rate decay parameters, and extract some of the image-model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential Learning Rate Decay Params\n",
    "learning_rate = 0.1\n",
    "lr_decay = 0.1\n",
    "num_gens_to_wait = 250.\n",
    "\n",
    "# Extract model parameters\n",
    "image_vec_length = image_height * image_width * num_channels\n",
    "record_length = 1 + image_vec_length # ( + 1 for the 0-9 label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the CIFAR-10 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_dir = 'temp'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "cifar10_url = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "\n",
    "# Check if file exists, otherwise download it\n",
    "data_file = os.path.join(data_dir, 'cifar-10-binary.tar.gz')\n",
    "if os.path.isfile(data_file):\n",
    "    pass\n",
    "else:\n",
    "    # Download file\n",
    "    def progress(block_num, block_size, total_size):\n",
    "        progress_info = [cifar10_url, float(block_num * block_size) / float(total_size) * 100.0]\n",
    "        print('\\r Downloading {} - {:.2f}%'.format(*progress_info), end=\"\")\n",
    "    filepath, _ = urllib.request.urlretrieve(cifar10_url, data_file, progress)\n",
    "    # Extract file\n",
    "    tarfile.open(filepath, 'r:gz').extractall(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a reading function that will load (and optionally distort the images slightly) for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CIFAR reader\n",
    "def read_cifar_files(filename_queue, distort_images = True):\n",
    "    reader = tf.FixedLengthRecordReader(record_bytes=record_length)\n",
    "    key, record_string = reader.read(filename_queue)\n",
    "    record_bytes = tf.decode_raw(record_string, tf.uint8)\n",
    "    image_label = tf.cast(tf.slice(record_bytes, [0], [1]), tf.int32)\n",
    "  \n",
    "    # Extract image\n",
    "    image_extracted = tf.reshape(tf.slice(record_bytes, [1], [image_vec_length]),\n",
    "                                 [num_channels, image_height, image_width])\n",
    "    \n",
    "    # Reshape image\n",
    "    image_uint8image = tf.transpose(image_extracted, [1, 2, 0])\n",
    "    reshaped_image = tf.cast(image_uint8image, tf.float32)\n",
    "    # Randomly Crop image\n",
    "    final_image = tf.image.resize_image_with_crop_or_pad(reshaped_image, crop_width, crop_height)\n",
    "    \n",
    "    if distort_images:\n",
    "        # Randomly flip the image horizontally, change the brightness and contrast\n",
    "        final_image = tf.image.random_flip_left_right(final_image)\n",
    "        final_image = tf.image.random_brightness(final_image,max_delta=63)\n",
    "        final_image = tf.image.random_contrast(final_image,lower=0.2, upper=1.8)\n",
    "\n",
    "    # Normalize whitening\n",
    "    final_image = tf.image.per_image_standardization(final_image)\n",
    "    return final_image, image_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above loading function in our image pipeline function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CIFAR image pipeline from reader\n",
    "def input_pipeline(batch_size, train_logical=True):\n",
    "    if train_logical:\n",
    "        files = [os.path.join(data_dir, extract_folder, 'data_batch_{}.bin'.format(i)) for i in range(1,6)]\n",
    "    else:\n",
    "        files = [os.path.join(data_dir, extract_folder, 'test_batch.bin')]\n",
    "    filename_queue = tf.train.string_input_producer(files)\n",
    "    image, label = read_cifar_files(filename_queue)\n",
    "    \n",
    "    # min_after_dequeue defines how big a buffer we will randomly sample\n",
    "    #   from -- bigger means better shuffling but slower start up and more\n",
    "    #   memory used.\n",
    "    # capacity must be larger than min_after_dequeue and the amount larger\n",
    "    #   determines the maximum we will prefetch.  Recommendation:\n",
    "    #   min_after_dequeue + (num_threads + a small safety margin) * batch_size\n",
    "    min_after_dequeue = 5000\n",
    "    capacity = min_after_dequeue + 3 * batch_size\n",
    "    example_batch, label_batch = tf.train.shuffle_batch([image, label],\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        capacity=capacity,\n",
    "                                                        min_after_dequeue=min_after_dequeue)\n",
    "\n",
    "    return example_batch, label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that returns our CIFAR-10 model architecture so that we can use it both for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture, this will return logits from images\n",
    "def cifar_cnn_model(input_images, batch_size, train_logical=True):\n",
    "    def truncated_normal_var(name, shape, dtype):\n",
    "        return(tf.get_variable(name=name, shape=shape, dtype=dtype, initializer=tf.truncated_normal_initializer(stddev=0.05)))\n",
    "    def zero_var(name, shape, dtype):\n",
    "        return(tf.get_variable(name=name, shape=shape, dtype=dtype, initializer=tf.constant_initializer(0.0)))\n",
    "    \n",
    "    # First Convolutional Layer\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        # Conv_kernel is 5x5 for all 3 colors and we will create 64 features\n",
    "        conv1_kernel = truncated_normal_var(name='conv_kernel1', shape=[5, 5, 3, 64], dtype=tf.float32)\n",
    "        # We convolve across the image with a stride size of 1\n",
    "        conv1 = tf.nn.conv2d(input_images, conv1_kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        # Initialize and add the bias term\n",
    "        conv1_bias = zero_var(name='conv_bias1', shape=[64], dtype=tf.float32)\n",
    "        conv1_add_bias = tf.nn.bias_add(conv1, conv1_bias)\n",
    "        # ReLU element wise\n",
    "        relu_conv1 = tf.nn.relu(conv1_add_bias)\n",
    "    \n",
    "    # Max Pooling\n",
    "    pool1 = tf.nn.max_pool(relu_conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],padding='SAME', name='pool_layer1')\n",
    "    \n",
    "    # Local Response Normalization (parameters from paper)\n",
    "    # paper: http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks\n",
    "    norm1 = tf.nn.lrn(pool1, depth_radius=5, bias=2.0, alpha=1e-3, beta=0.75, name='norm1')\n",
    "\n",
    "    # Second Convolutional Layer\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        # Conv kernel is 5x5, across all prior 64 features and we create 64 more features\n",
    "        conv2_kernel = truncated_normal_var(name='conv_kernel2', shape=[5, 5, 64, 64], dtype=tf.float32)\n",
    "        # Convolve filter across prior output with stride size of 1\n",
    "        conv2 = tf.nn.conv2d(norm1, conv2_kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        # Initialize and add the bias\n",
    "        conv2_bias = zero_var(name='conv_bias2', shape=[64], dtype=tf.float32)\n",
    "        conv2_add_bias = tf.nn.bias_add(conv2, conv2_bias)\n",
    "        # ReLU element wise\n",
    "        relu_conv2 = tf.nn.relu(conv2_add_bias)\n",
    "    \n",
    "    # Max Pooling\n",
    "    pool2 = tf.nn.max_pool(relu_conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool_layer2')    \n",
    "    \n",
    "     # Local Response Normalization (parameters from paper)\n",
    "    norm2 = tf.nn.lrn(pool2, depth_radius=5, bias=2.0, alpha=1e-3, beta=0.75, name='norm2')\n",
    "    \n",
    "    # Reshape output into a single matrix for multiplication for the fully connected layers\n",
    "    reshaped_output = tf.reshape(norm2, [batch_size, -1])\n",
    "    reshaped_dim = reshaped_output.get_shape()[1].value\n",
    "    \n",
    "    # First Fully Connected Layer\n",
    "    with tf.variable_scope('full1') as scope:\n",
    "        # Fully connected layer will have 384 outputs.\n",
    "        full_weight1 = truncated_normal_var(name='full_mult1', shape=[reshaped_dim, 384], dtype=tf.float32)\n",
    "        full_bias1 = zero_var(name='full_bias1', shape=[384], dtype=tf.float32)\n",
    "        full_layer1 = tf.nn.relu(tf.add(tf.matmul(reshaped_output, full_weight1), full_bias1))\n",
    "\n",
    "    # Second Fully Connected Layer\n",
    "    with tf.variable_scope('full2') as scope:\n",
    "        # Second fully connected layer has 192 outputs.\n",
    "        full_weight2 = truncated_normal_var(name='full_mult2', shape=[384, 192], dtype=tf.float32)\n",
    "        full_bias2 = zero_var(name='full_bias2', shape=[192], dtype=tf.float32)\n",
    "        full_layer2 = tf.nn.relu(tf.add(tf.matmul(full_layer1, full_weight2), full_bias2))\n",
    "\n",
    "    # Final Fully Connected Layer -> 10 categories for output (num_targets)\n",
    "    with tf.variable_scope('full3') as scope:\n",
    "        # Final fully connected layer has 10 (num_targets) outputs.\n",
    "        full_weight3 = truncated_normal_var(name='full_mult3', shape=[192, num_targets], dtype=tf.float32)\n",
    "        full_bias3 =  zero_var(name='full_bias3', shape=[num_targets], dtype=tf.float32)\n",
    "        final_output = tf.add(tf.matmul(full_layer2, full_weight3), full_bias3)\n",
    "        \n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our loss function.  Our loss will be the average cross entropy loss (categorical loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def cifar_loss(logits, targets):\n",
    "    # Get rid of extra dimensions and cast targets into integers\n",
    "    targets = tf.squeeze(tf.cast(targets, tf.int32))\n",
    "    # Calculate cross entropy from logits and targets\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=targets)\n",
    "    # Take the average loss across batch size\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "    return cross_entropy_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our training step.  Here we will use exponential decay of the learning rate, declare the optimizer and tell the training step to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train step\n",
    "def train_step(loss_value, generation_num):\n",
    "    # Our learning rate is an exponential decay after we wait a fair number of generations\n",
    "    model_learning_rate = tf.train.exponential_decay(learning_rate, generation_num,\n",
    "                                                     num_gens_to_wait, lr_decay, staircase=True)\n",
    "    # Create optimizer\n",
    "    my_optimizer = tf.train.GradientDescentOptimizer(model_learning_rate)\n",
    "    # Initialize train step\n",
    "    train_step = my_optimizer.minimize(loss_value)\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an accuracy function that takes in the predicted logits from the model and the actual targets and returns the accuracy for recording statistics on the train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy function\n",
    "def accuracy_of_batch(logits, targets):\n",
    "    # Make sure targets are integers and drop extra dimensions\n",
    "    targets = tf.squeeze(tf.cast(targets, tf.int32))\n",
    "    # Get predicted values by finding which logit is the greatest\n",
    "    batch_predictions = tf.cast(tf.argmax(logits, 1), tf.int32)\n",
    "    # Check if they are equal across the batch\n",
    "    predicted_correctly = tf.equal(batch_predictions, targets)\n",
    "    # Average the 1's and 0's (True's and False's) across the batch size\n",
    "    accuracy = tf.reduce_mean(tf.cast(predicted_correctly, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all our functions we need, let's use them to create\n",
    "\n",
    "  1. our data pipeline\n",
    "  \n",
    "  2. our model\n",
    "  \n",
    "  3. the evaluations/accuracy/training operations.\n",
    "\n",
    "First our data pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting/Transforming Data.\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "print('Getting/Transforming Data.')\n",
    "# Initialize the data pipeline\n",
    "images, targets = input_pipeline(batch_size, train_logical=True)\n",
    "# Get batch test images and targets from pipline\n",
    "test_images, test_targets = input_pipeline(batch_size, train_logical=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our model.\n",
    "\n",
    "Note: Be careful not to accidentally run the following model-creation code twice without resetting the computational graph.  If you do, you will end up with variable-sharing errors.  If that is the case, re-run the whole script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the CIFAR10 Model.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Declare Model\n",
    "print('Creating the CIFAR10 Model.')\n",
    "with tf.variable_scope('model_definition') as scope:\n",
    "    # Declare the training network model\n",
    "    model_output = cifar_cnn_model(images, batch_size)\n",
    "    # This is very important!!!  We must set the scope to REUSE the variables,\n",
    "    #  otherwise, when we set the test network model, it will create new random\n",
    "    #  variables.  Otherwise we get random evaluations on the test batches.\n",
    "    scope.reuse_variables()\n",
    "    test_output = cifar_cnn_model(test_images, batch_size)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss and accuracy functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declare Loss Function.\n"
     ]
    }
   ],
   "source": [
    "# Declare loss function\n",
    "print('Declare Loss Function.')\n",
    "loss = cifar_loss(model_output, targets)\n",
    "\n",
    "# Create accuracy function\n",
    "accuracy = accuracy_of_batch(test_output, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the training operations and initialize our model variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the Training Operation.\n",
      "Initializing the Variables.\n"
     ]
    }
   ],
   "source": [
    "# Create training operations\n",
    "print('Creating the Training Operation.')\n",
    "generation_num = tf.Variable(0, trainable=False)\n",
    "train_op = train_step(loss, generation_num)\n",
    "\n",
    "# Initialize Variables\n",
    "print('Initializing the Variables.')\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we initialize our data queue.  This is an operation that will feed data into our model. Because of this _no placeholders are necessary_!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Thread(QueueRunnerThread-input_producer-input_producer/input_producer_EnqueueMany, started daemon 140554214045440)>,\n",
       " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140554205652736)>,\n",
       " <Thread(QueueRunnerThread-input_producer_1-input_producer_1/input_producer_1_EnqueueMany, started daemon 140554176296704)>,\n",
       " <Thread(QueueRunnerThread-shuffle_batch_1/random_shuffle_queue-shuffle_batch_1/random_shuffle_queue_enqueue, started daemon 140553878501120)>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize queue (This queue will feed into the model, so no placeholders necessary)\n",
    "tf.train.start_queue_runners(sess=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training our CIFAR-10 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Generation 50: Loss = 2.22219\n",
      "Generation 100: Loss = 1.85807\n",
      "Generation 150: Loss = 1.68547\n",
      "Generation 200: Loss = 1.68184\n",
      "Generation 250: Loss = 1.74119\n",
      "Generation 300: Loss = 1.38158\n",
      "Generation 350: Loss = 1.65851\n",
      "Generation 400: Loss = 1.40172\n",
      "Generation 450: Loss = 1.57229\n",
      "Generation 500: Loss = 1.52364\n",
      " --- Test Accuracy = 48.44%.\n",
      "Generation 550: Loss = 1.54652\n",
      "Generation 600: Loss = 1.21434\n",
      "Generation 650: Loss = 1.15258\n",
      "Generation 700: Loss = 1.40707\n",
      "Generation 750: Loss = 1.22228\n",
      "Generation 800: Loss = 1.63065\n",
      "Generation 850: Loss = 0.99193\n",
      "Generation 900: Loss = 1.22815\n",
      "Generation 950: Loss = 1.32409\n",
      "Generation 1000: Loss = 1.15603\n",
      " --- Test Accuracy = 61.72%.\n",
      "Generation 1050: Loss = 1.18986\n",
      "Generation 1100: Loss = 1.29607\n",
      "Generation 1150: Loss = 1.06038\n",
      "Generation 1200: Loss = 1.08335\n",
      "Generation 1250: Loss = 0.92217\n",
      "Generation 1300: Loss = 1.07797\n",
      "Generation 1350: Loss = 0.98897\n",
      "Generation 1400: Loss = 0.90099\n",
      "Generation 1450: Loss = 1.15199\n",
      "Generation 1500: Loss = 0.96269\n",
      " --- Test Accuracy = 66.41%.\n",
      "Generation 1550: Loss = 1.04298\n",
      "Generation 1600: Loss = 1.07072\n",
      "Generation 1650: Loss = 0.92319\n",
      "Generation 1700: Loss = 0.92984\n",
      "Generation 1750: Loss = 1.06442\n",
      "Generation 1800: Loss = 1.00948\n",
      "Generation 1850: Loss = 0.87709\n",
      "Generation 1900: Loss = 0.84341\n",
      "Generation 1950: Loss = 1.03165\n",
      "Generation 2000: Loss = 0.93634\n",
      " --- Test Accuracy = 71.09%.\n",
      "Generation 2050: Loss = 0.96792\n",
      "Generation 2100: Loss = 0.95701\n",
      "Generation 2150: Loss = 0.98133\n",
      "Generation 2200: Loss = 0.77839\n",
      "Generation 2250: Loss = 0.78996\n",
      "Generation 2300: Loss = 0.64711\n",
      "Generation 2350: Loss = 0.83760\n",
      "Generation 2400: Loss = 0.87779\n",
      "Generation 2450: Loss = 0.74253\n",
      "Generation 2500: Loss = 1.06014\n",
      " --- Test Accuracy = 67.19%.\n",
      "Generation 2550: Loss = 0.98001\n",
      "Generation 2600: Loss = 0.72652\n",
      "Generation 2650: Loss = 0.83733\n",
      "Generation 2700: Loss = 0.75945\n",
      "Generation 2750: Loss = 0.66448\n",
      "Generation 2800: Loss = 0.51232\n",
      "Generation 2850: Loss = 0.88612\n",
      "Generation 2900: Loss = 0.84675\n",
      "Generation 2950: Loss = 0.68100\n",
      "Generation 3000: Loss = 0.65376\n",
      " --- Test Accuracy = 71.09%.\n",
      "Generation 3050: Loss = 0.71898\n",
      "Generation 3100: Loss = 0.57456\n",
      "Generation 3150: Loss = 0.72935\n",
      "Generation 3200: Loss = 0.78159\n",
      "Generation 3250: Loss = 0.69169\n",
      "Generation 3300: Loss = 0.56033\n",
      "Generation 3350: Loss = 0.64748\n",
      "Generation 3400: Loss = 0.87948\n",
      "Generation 3450: Loss = 0.65140\n",
      "Generation 3500: Loss = 0.51259\n",
      " --- Test Accuracy = 75.00%.\n",
      "Generation 3550: Loss = 0.82033\n",
      "Generation 3600: Loss = 0.71675\n",
      "Generation 3650: Loss = 0.70801\n",
      "Generation 3700: Loss = 0.55834\n",
      "Generation 3750: Loss = 0.70787\n",
      "Generation 3800: Loss = 0.73251\n",
      "Generation 3850: Loss = 0.77875\n",
      "Generation 3900: Loss = 0.63775\n",
      "Generation 3950: Loss = 0.63114\n",
      "Generation 4000: Loss = 0.65832\n",
      " --- Test Accuracy = 73.44%.\n",
      "Generation 4050: Loss = 0.59112\n",
      "Generation 4100: Loss = 0.56239\n",
      "Generation 4150: Loss = 0.48473\n",
      "Generation 4200: Loss = 0.60673\n",
      "Generation 4250: Loss = 0.54643\n",
      "Generation 4300: Loss = 0.36085\n",
      "Generation 4350: Loss = 0.51280\n",
      "Generation 4400: Loss = 0.47175\n",
      "Generation 4450: Loss = 0.49959\n",
      "Generation 4500: Loss = 0.58502\n",
      " --- Test Accuracy = 72.66%.\n",
      "Generation 4550: Loss = 0.58235\n",
      "Generation 4600: Loss = 0.45179\n",
      "Generation 4650: Loss = 0.56750\n",
      "Generation 4700: Loss = 0.65299\n",
      "Generation 4750: Loss = 0.70526\n",
      "Generation 4800: Loss = 0.47422\n",
      "Generation 4850: Loss = 0.48375\n",
      "Generation 4900: Loss = 0.52676\n",
      "Generation 4950: Loss = 0.52289\n",
      "Generation 5000: Loss = 0.50192\n",
      " --- Test Accuracy = 71.88%.\n",
      "Generation 5050: Loss = 0.59892\n",
      "Generation 5100: Loss = 0.45527\n",
      "Generation 5150: Loss = 0.53386\n",
      "Generation 5200: Loss = 0.77476\n",
      "Generation 5250: Loss = 0.54141\n",
      "Generation 5300: Loss = 0.51670\n",
      "Generation 5350: Loss = 0.49446\n",
      "Generation 5400: Loss = 0.49188\n",
      "Generation 5450: Loss = 0.50857\n",
      "Generation 5500: Loss = 0.50068\n",
      " --- Test Accuracy = 72.66%.\n",
      "Generation 5550: Loss = 0.59581\n",
      "Generation 5600: Loss = 0.52229\n",
      "Generation 5650: Loss = 0.47215\n",
      "Generation 5700: Loss = 0.42330\n",
      "Generation 5750: Loss = 0.34450\n",
      "Generation 5800: Loss = 0.36536\n",
      "Generation 5850: Loss = 0.42827\n",
      "Generation 5900: Loss = 0.44538\n",
      "Generation 5950: Loss = 0.30317\n",
      "Generation 6000: Loss = 0.41827\n",
      " --- Test Accuracy = 66.41%.\n",
      "Generation 6050: Loss = 0.45309\n",
      "Generation 6100: Loss = 0.53218\n",
      "Generation 6150: Loss = 0.54768\n",
      "Generation 6200: Loss = 0.39211\n",
      "Generation 6250: Loss = 0.39908\n",
      "Generation 6300: Loss = 0.38738\n",
      "Generation 6350: Loss = 0.34731\n",
      "Generation 6400: Loss = 0.35364\n",
      "Generation 6450: Loss = 0.34350\n",
      "Generation 6500: Loss = 0.38413\n",
      " --- Test Accuracy = 69.53%.\n",
      "Generation 6550: Loss = 0.34716\n",
      "Generation 6600: Loss = 0.36041\n",
      "Generation 6650: Loss = 0.31626\n",
      "Generation 6700: Loss = 0.35847\n",
      "Generation 6750: Loss = 0.34144\n",
      "Generation 6800: Loss = 0.39028\n",
      "Generation 6850: Loss = 0.36830\n",
      "Generation 6900: Loss = 0.32516\n",
      "Generation 6950: Loss = 0.45589\n",
      "Generation 7000: Loss = 0.36049\n",
      " --- Test Accuracy = 74.22%.\n",
      "Generation 7050: Loss = 0.30818\n",
      "Generation 7100: Loss = 0.29933\n",
      "Generation 7150: Loss = 0.41084\n",
      "Generation 7200: Loss = 0.29161\n",
      "Generation 7250: Loss = 0.37509\n",
      "Generation 7300: Loss = 0.35893\n",
      "Generation 7350: Loss = 0.53219\n",
      "Generation 7400: Loss = 0.31675\n",
      "Generation 7450: Loss = 0.40996\n",
      "Generation 7500: Loss = 0.33220\n",
      " --- Test Accuracy = 78.91%.\n",
      "Generation 7550: Loss = 0.29118\n",
      "Generation 7600: Loss = 0.41889\n",
      "Generation 7650: Loss = 0.57657\n",
      "Generation 7700: Loss = 0.29782\n",
      "Generation 7750: Loss = 0.43187\n",
      "Generation 7800: Loss = 0.25003\n",
      "Generation 7850: Loss = 0.45441\n",
      "Generation 7900: Loss = 0.39218\n",
      "Generation 7950: Loss = 0.27209\n",
      "Generation 8000: Loss = 0.26593\n",
      " --- Test Accuracy = 71.09%.\n",
      "Generation 8050: Loss = 0.29173\n",
      "Generation 8100: Loss = 0.20581\n",
      "Generation 8150: Loss = 0.28751\n",
      "Generation 8200: Loss = 0.25576\n",
      "Generation 8250: Loss = 0.23699\n",
      "Generation 8300: Loss = 0.36858\n",
      "Generation 8350: Loss = 0.31646\n",
      "Generation 8400: Loss = 0.34488\n",
      "Generation 8450: Loss = 0.37525\n",
      "Generation 8500: Loss = 0.35619\n",
      " --- Test Accuracy = 70.31%.\n",
      "Generation 8550: Loss = 0.36015\n",
      "Generation 8600: Loss = 0.24438\n",
      "Generation 8650: Loss = 0.20174\n",
      "Generation 8700: Loss = 0.27228\n",
      "Generation 8750: Loss = 0.23897\n",
      "Generation 8800: Loss = 0.30986\n",
      "Generation 8850: Loss = 0.26505\n",
      "Generation 8900: Loss = 0.31545\n",
      "Generation 8950: Loss = 0.21516\n",
      "Generation 9000: Loss = 0.21046\n",
      " --- Test Accuracy = 76.56%.\n",
      "Generation 9050: Loss = 0.28550\n",
      "Generation 9100: Loss = 0.27660\n",
      "Generation 9150: Loss = 0.17356\n",
      "Generation 9200: Loss = 0.38091\n",
      "Generation 9250: Loss = 0.27599\n",
      "Generation 9300: Loss = 0.25478\n",
      "Generation 9350: Loss = 0.16506\n",
      "Generation 9400: Loss = 0.14490\n",
      "Generation 9450: Loss = 0.11816\n",
      "Generation 9500: Loss = 0.20271\n",
      " --- Test Accuracy = 73.44%.\n",
      "Generation 9550: Loss = 0.30426\n",
      "Generation 9600: Loss = 0.28590\n",
      "Generation 9650: Loss = 0.23571\n",
      "Generation 9700: Loss = 0.24250\n",
      "Generation 9750: Loss = 0.24284\n",
      "Generation 9800: Loss = 0.09817\n",
      "Generation 9850: Loss = 0.12160\n",
      "Generation 9900: Loss = 0.32002\n",
      "Generation 9950: Loss = 0.13505\n",
      "Generation 10000: Loss = 0.20079\n",
      " --- Test Accuracy = 68.75%.\n",
      "Generation 10050: Loss = 0.31114\n",
      "Generation 10100: Loss = 0.42379\n",
      "Generation 10150: Loss = 0.20613\n",
      "Generation 10200: Loss = 0.15331\n",
      "Generation 10250: Loss = 0.15261\n",
      "Generation 10300: Loss = 0.14211\n",
      "Generation 10350: Loss = 0.16100\n",
      "Generation 10400: Loss = 0.15507\n",
      "Generation 10450: Loss = 0.13907\n",
      "Generation 10500: Loss = 0.23206\n",
      " --- Test Accuracy = 75.78%.\n",
      "Generation 10550: Loss = 0.16987\n",
      "Generation 10600: Loss = 0.23998\n",
      "Generation 10650: Loss = 0.11580\n",
      "Generation 10700: Loss = 0.17190\n",
      "Generation 10750: Loss = 0.15540\n",
      "Generation 10800: Loss = 0.07270\n",
      "Generation 10850: Loss = 0.37539\n",
      "Generation 10900: Loss = 0.11713\n",
      "Generation 10950: Loss = 0.10872\n",
      "Generation 11000: Loss = 0.13500\n",
      " --- Test Accuracy = 82.03%.\n",
      "Generation 11050: Loss = 0.20937\n",
      "Generation 11100: Loss = 0.16623\n",
      "Generation 11150: Loss = 0.20023\n",
      "Generation 11200: Loss = 0.16487\n",
      "Generation 11250: Loss = 0.11642\n",
      "Generation 11300: Loss = 0.18679\n",
      "Generation 11350: Loss = 0.18241\n",
      "Generation 11400: Loss = 0.30240\n",
      "Generation 11450: Loss = 0.16756\n",
      "Generation 11500: Loss = 0.12587\n",
      " --- Test Accuracy = 75.00%.\n",
      "Generation 11550: Loss = 0.11192\n",
      "Generation 11600: Loss = 0.13776\n",
      "Generation 11650: Loss = 0.13892\n",
      "Generation 11700: Loss = 0.09813\n",
      "Generation 11750: Loss = 0.16972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 11800: Loss = 0.08673\n",
      "Generation 11850: Loss = 0.15599\n",
      "Generation 11900: Loss = 0.23680\n",
      "Generation 11950: Loss = 0.20358\n",
      "Generation 12000: Loss = 0.12177\n",
      " --- Test Accuracy = 76.56%.\n",
      "Generation 12050: Loss = 0.08545\n",
      "Generation 12100: Loss = 0.09663\n",
      "Generation 12150: Loss = 0.10876\n",
      "Generation 12200: Loss = 0.09189\n",
      "Generation 12250: Loss = 0.24599\n",
      "Generation 12300: Loss = 0.15975\n",
      "Generation 12350: Loss = 0.10316\n",
      "Generation 12400: Loss = 0.11794\n",
      "Generation 12450: Loss = 0.13761\n",
      "Generation 12500: Loss = 0.14217\n",
      " --- Test Accuracy = 77.34%.\n",
      "Generation 12550: Loss = 0.08080\n",
      "Generation 12600: Loss = 0.16124\n",
      "Generation 12650: Loss = 0.12760\n",
      "Generation 12700: Loss = 0.11007\n",
      "Generation 12750: Loss = 0.12987\n",
      "Generation 12800: Loss = 0.15755\n",
      "Generation 12850: Loss = 0.12064\n",
      "Generation 12900: Loss = 0.14124\n",
      "Generation 12950: Loss = 0.09701\n",
      "Generation 13000: Loss = 0.10831\n",
      " --- Test Accuracy = 78.12%.\n",
      "Generation 13050: Loss = 0.07502\n",
      "Generation 13100: Loss = 0.12954\n",
      "Generation 13150: Loss = 0.12065\n",
      "Generation 13200: Loss = 0.22691\n",
      "Generation 13250: Loss = 0.12308\n",
      "Generation 13300: Loss = 0.10805\n",
      "Generation 13350: Loss = 0.06780\n",
      "Generation 13400: Loss = 0.09669\n",
      "Generation 13450: Loss = 0.06341\n",
      "Generation 13500: Loss = 0.12197\n",
      " --- Test Accuracy = 75.78%.\n",
      "Generation 13550: Loss = 0.23862\n",
      "Generation 13600: Loss = 0.10103\n",
      "Generation 13650: Loss = 0.20902\n",
      "Generation 13700: Loss = 0.11332\n",
      "Generation 13750: Loss = 0.08335\n",
      "Generation 13800: Loss = 0.08663\n",
      "Generation 13850: Loss = 0.12625\n",
      "Generation 13900: Loss = 0.05864\n",
      "Generation 13950: Loss = 0.17451\n",
      "Generation 14000: Loss = 0.13627\n",
      " --- Test Accuracy = 70.31%.\n",
      "Generation 14050: Loss = 0.20784\n",
      "Generation 14100: Loss = 0.11717\n",
      "Generation 14150: Loss = 0.03854\n",
      "Generation 14200: Loss = 0.06526\n",
      "Generation 14250: Loss = 0.26731\n",
      "Generation 14300: Loss = 0.07495\n",
      "Generation 14350: Loss = 0.09222\n",
      "Generation 14400: Loss = 0.15696\n",
      "Generation 14450: Loss = 0.04297\n",
      "Generation 14500: Loss = 0.07677\n",
      " --- Test Accuracy = 70.31%.\n",
      "Generation 14550: Loss = 0.09991\n",
      "Generation 14600: Loss = 0.11924\n",
      "Generation 14650: Loss = 0.05325\n",
      "Generation 14700: Loss = 0.03364\n",
      "Generation 14750: Loss = 0.14391\n",
      "Generation 14800: Loss = 0.10284\n",
      "Generation 14850: Loss = 0.07053\n",
      "Generation 14900: Loss = 0.07664\n",
      "Generation 14950: Loss = 0.05674\n",
      "Generation 15000: Loss = 0.11531\n",
      " --- Test Accuracy = 78.91%.\n",
      "Generation 15050: Loss = 0.04956\n",
      "Generation 15100: Loss = 0.16902\n",
      "Generation 15150: Loss = 0.05712\n",
      "Generation 15200: Loss = 0.14315\n",
      "Generation 15250: Loss = 0.07237\n",
      "Generation 15300: Loss = 0.08642\n",
      "Generation 15350: Loss = 0.05745\n",
      "Generation 15400: Loss = 0.07474\n",
      "Generation 15450: Loss = 0.07620\n",
      "Generation 15500: Loss = 0.08292\n",
      " --- Test Accuracy = 72.66%.\n",
      "Generation 15550: Loss = 0.07901\n",
      "Generation 15600: Loss = 0.10158\n",
      "Generation 15650: Loss = 0.06576\n",
      "Generation 15700: Loss = 0.03132\n",
      "Generation 15750: Loss = 0.04647\n",
      "Generation 15800: Loss = 0.04733\n",
      "Generation 15850: Loss = 0.08735\n",
      "Generation 15900: Loss = 0.08469\n",
      "Generation 15950: Loss = 0.10317\n",
      "Generation 16000: Loss = 0.14254\n",
      " --- Test Accuracy = 67.19%.\n",
      "Generation 16050: Loss = 0.07889\n",
      "Generation 16100: Loss = 0.03838\n",
      "Generation 16150: Loss = 1.56871\n",
      "Generation 16200: Loss = 0.29074\n",
      "Generation 16250: Loss = 0.11173\n",
      "Generation 16300: Loss = 0.18879\n",
      "Generation 16350: Loss = 0.08717\n",
      "Generation 16400: Loss = 0.08106\n",
      "Generation 16450: Loss = 0.06831\n",
      "Generation 16500: Loss = 0.02831\n",
      " --- Test Accuracy = 75.00%.\n",
      "Generation 16550: Loss = 0.02745\n",
      "Generation 16600: Loss = 0.11969\n",
      "Generation 16650: Loss = 0.09231\n",
      "Generation 16700: Loss = 0.04571\n",
      "Generation 16750: Loss = 0.05827\n",
      "Generation 16800: Loss = 0.05583\n",
      "Generation 16850: Loss = 0.02678\n",
      "Generation 16900: Loss = 0.04999\n",
      "Generation 16950: Loss = 0.02827\n",
      "Generation 17000: Loss = 0.05910\n",
      " --- Test Accuracy = 75.78%.\n",
      "Generation 17050: Loss = 0.07838\n",
      "Generation 17100: Loss = 0.06673\n",
      "Generation 17150: Loss = 0.05559\n",
      "Generation 17200: Loss = 0.06485\n",
      "Generation 17250: Loss = 0.06158\n",
      "Generation 17300: Loss = 0.03602\n",
      "Generation 17350: Loss = 0.05485\n",
      "Generation 17400: Loss = 0.02631\n",
      "Generation 17450: Loss = 0.13610\n",
      "Generation 17500: Loss = 0.04200\n",
      " --- Test Accuracy = 79.69%.\n",
      "Generation 17550: Loss = 0.10818\n",
      "Generation 17600: Loss = 0.06108\n",
      "Generation 17650: Loss = 0.05695\n",
      "Generation 17700: Loss = 0.04235\n",
      "Generation 17750: Loss = 0.02394\n",
      "Generation 17800: Loss = 0.05784\n",
      "Generation 17850: Loss = 0.05994\n",
      "Generation 17900: Loss = 0.06085\n",
      "Generation 17950: Loss = 0.05327\n",
      "Generation 18000: Loss = 0.06379\n",
      " --- Test Accuracy = 74.22%.\n",
      "Generation 18050: Loss = 0.04180\n",
      "Generation 18100: Loss = 0.08503\n",
      "Generation 18150: Loss = 0.08361\n",
      "Generation 18200: Loss = 0.05335\n",
      "Generation 18250: Loss = 0.09445\n",
      "Generation 18300: Loss = 0.05537\n",
      "Generation 18350: Loss = 0.04895\n",
      "Generation 18400: Loss = 0.04671\n",
      "Generation 18450: Loss = 0.08520\n",
      "Generation 18500: Loss = 0.07298\n",
      " --- Test Accuracy = 75.00%.\n",
      "Generation 18550: Loss = 0.03096\n",
      "Generation 18600: Loss = 0.03646\n",
      "Generation 18650: Loss = 0.04376\n",
      "Generation 18700: Loss = 0.04119\n",
      "Generation 18750: Loss = 0.05245\n",
      "Generation 18800: Loss = 0.03907\n",
      "Generation 18850: Loss = 0.06135\n",
      "Generation 18900: Loss = 0.03612\n",
      "Generation 18950: Loss = 0.10236\n",
      "Generation 19000: Loss = 0.27241\n",
      " --- Test Accuracy = 76.56%.\n",
      "Generation 19050: Loss = 0.01347\n",
      "Generation 19100: Loss = 0.09993\n",
      "Generation 19150: Loss = 0.01865\n",
      "Generation 19200: Loss = 0.04441\n",
      "Generation 19250: Loss = 0.05128\n",
      "Generation 19300: Loss = 0.00984\n",
      "Generation 19350: Loss = 0.05635\n",
      "Generation 19400: Loss = 0.13634\n",
      "Generation 19450: Loss = 0.04376\n",
      "Generation 19500: Loss = 0.01479\n",
      " --- Test Accuracy = 73.44%.\n",
      "Generation 19550: Loss = 0.05829\n",
      "Generation 19600: Loss = 0.03087\n",
      "Generation 19650: Loss = 0.03926\n",
      "Generation 19700: Loss = 0.01886\n",
      "Generation 19750: Loss = 0.02823\n",
      "Generation 19800: Loss = 0.03191\n",
      "Generation 19850: Loss = 0.08998\n",
      "Generation 19900: Loss = 0.05946\n",
      "Generation 19950: Loss = 0.02510\n",
      "Generation 20000: Loss = 0.02570\n",
      " --- Test Accuracy = 80.47%.\n"
     ]
    }
   ],
   "source": [
    "# Train CIFAR Model\n",
    "print('Starting Training')\n",
    "train_loss = []\n",
    "test_accuracy = []\n",
    "for i in range(generations):\n",
    "    _, loss_value = sess.run([train_op, loss])\n",
    "    \n",
    "    if (i+1) % output_every == 0:\n",
    "        train_loss.append(loss_value)\n",
    "        output = 'Generation {}: Loss = {:.5f}'.format((i+1), loss_value)\n",
    "        print(output)\n",
    "    \n",
    "    if (i+1) % eval_every == 0:\n",
    "        [temp_accuracy] = sess.run([accuracy])\n",
    "        test_accuracy.append(temp_accuracy)\n",
    "        acc_output = ' --- Test Accuracy = {:.2f}%.'.format(100.*temp_accuracy)\n",
    "        print(acc_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print loss and accuracy\n",
    "# Matlotlib code to plot the loss and accuracies\n",
    "eval_indices = range(0, generations, eval_every)\n",
    "output_indices = range(0, generations, output_every)\n",
    "\n",
    "# Plot loss over time\n",
    "plt.plot(output_indices, train_loss, 'k-')\n",
    "plt.title('Softmax Loss per Generation')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Softmax Loss')\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy over time\n",
    "plt.plot(eval_indices, test_accuracy, 'k-')\n",
    "plt.title('Test Accuracy')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
